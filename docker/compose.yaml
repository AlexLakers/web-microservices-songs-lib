services:
  database:
    image: postgres:17
    ports:
      - 5442:5432
    environment:
      POSTGRES_USER: adminauthor
      POSTGRES_PASSWORD: AdminAuthor
      POSTGRES_DB: songs_lib_author_dev
    volumes:
      - db-data:/var/lib/postgres/data
    networks:
      backend-net:
        aliases:
          - database
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U postgres" ]
      interval: 10s
      timeout: 5s
      retries: 5
  databasetwo:
    image: postgres:17
    ports:
      - 5452:5432
    environment:
      POSTGRES_USER: adminsong
      POSTGRES_PASSWORD: AdminSong
      POSTGRES_DB: songs_lib_song_dev
    volumes:
      - db-data-two:/var/lib/postgres/data
    networks:
      backend-net:
        aliases:
          - databasetwo
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U postgres" ]
      interval: 10s
      timeout: 5s
      retries: 5

  configserver:
    image: songs-lib/config-server:0.0.1-SNAPSHOT
    networks:
      backend-net:
        aliases:
          - configserver
    ports:
      - 8888:8888
    #environment:
      #ENCRYPT_KEY: fje83Ki8403Iod87dne7Yjsl3THueh48jfuO9j4U2hf64Lo
  authorservice:
    image: songs-lib/author-service:0.0.1-SNAPSHOT
    depends_on:
      database:
        condition: service_healthy
      configserver:
        condition: service_started
    environment:
      SPRING_PROFILES_ACTIVE: dev
      SPRING_DATASOURCE_URL: jdbc:postgresql://database:5432/songs_lib_author_dev
    networks:
      backend-net:
        aliases:
            - authorservice
    ports:
      - 8086:8086
  songservice:
    image: songs-lib/song-service:0.0.1-SNAPSHOT
    depends_on:
      databasetwo:
        condition: service_healthy
      configserver:
        condition: service_started
    environment:
      SPRING_PROFILES_ACTIVE: dev
      SPRING_DATASOURCE_URL: jdbc:postgresql://databasetwo:5432/songs_lib_song_dev
    networks:
      backend-net:
        aliases:
          - songservice
    ports:
      - 8089:8089
  eurekaserver:
    image: songs-lib/eureka-server:0.0.1-SNAPSHOT
    depends_on:
      configserver:
        condition: service_started
    networks:
      backend-net:
        aliases:
            - eurekaserver
    ports:
      - 8081:8081
  gatewayserver:
    image: songs-lib/gateway-server:1.0-SNAPSHOT
    ports:
      - 8072:8072
    depends_on:
      configserver:
        condition: service_started
    networks:
      backend-net:
        aliases:
            - gatewayserver
  keycloak:
    image: quay.io/keycloak/keycloak:24.0.2
    environment:
      KEYCLOAK_ADMIN: admin
      KEYCLOAK_ADMIN_PASSWORD: admin
      KEYCLOAK_HTTP_HOST: 0.0.0.0
    ports:
      - 8080:8080
    #restart: always
    volumes:
      - ./realm-export.json:/opt/jboss/keycloak/realm-export.json
    command:
      - start-dev
    networks:
      backend-net:
        aliases:
          - keycloak
  frontendclient:
    image: songs-lib/frontend-client:1.0-SNAPSHOT
    depends_on:
      gatewayserver:
        condition: service_started
    ports:
      - 8089:8089
    networks:
      backend-net:
        aliases:
          - frontend
  redisserver:
    image: redis:alpine
    ports:
      - 6379:6379
    environment:
      REDIS_PASSWORD: mypass
    command: [ "sh", "-c","exec redis-server --requirepass mypass" ]
    #command: redis-server --requirepass $$REDIS_PASSWORD
    networks:
      backend-net:
        aliases:
          - redisserver
  elasticsearch:
    image: elasticsearch:7.17.1
    # volumes:
    # - esdata1:/usr/share/elasticsearch/data
    ports:
      - 9300:9300 #for communication with cluster
      - 9200:9200 #for REST
    volumes:
      - myesdata:/usr/share/elasticsearch/data/
    environment:
      ES_JAVA_OPTS: -Xmx512m -Xms512m
      ELASTIC_USERNAME: elastic
      ELASTIC_PASSWORD: MyPw123
      discovery.type: single-node
    networks:
      backend-net:
        aliases:
          - elasticsearch
  logstash:
    image: logstash:7.16.1 #docker.elastic.co/logstash/logstash:7.11.1
    command:
      logstash -f /etc/logstash/conf.d/logstash.conf
    volumes:
      - ./config:/etc/logstash/conf.d
    ports:
      - 5000:5000
    networks:
      backend-net:
        aliases:
          - logstash
  kibana:
    image: kibana:7.16.1
    environment:
      ELASTICSEARCH_URL: "http://elasticsearch:9300"
    ports:
      - 5601:5601
    networks:
      backend-net:
        aliases:
          - kibana
  zipkin:
    image: openzipkin/zipkin
    ports:
      - 9411:9411
    depends_on:
      - elasticsearch
    environment:
      STORAGE_TYPE: elasticsearch
      ES_HOSTS: elasticsearch:9300
    networks:
      backend-net:
        aliases:
          - zipkin
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    container_name: prometheus
    networks:
      backend-net:
        aliases:
          - "prometheus"
  grafana:
    image: "grafana/grafana:latest"
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=password
    container_name: grafana
    networks:
      backend-net:
        aliases:
          - "grafana"
  zookeeper:
    image: zookeeper
    ports:
      - 2181:2181
    healthcheck:
      test: [ "CMD","zkServer.sh","status" ]
      interval: 10s
      timeout: 5s
      retries: 05
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      backend-net:
        aliases:
          - zookeeper
  kafkaserver:
    image: docker.io/bitnami/kafka:3.5 #confluentinc/cp-kafka:latest #docker.io/bitnami/kafka:3.5 # or apache/kafka -new versions
    ports:
      - 9092:9092 #fmain port kafka
      - 29092:29092 #alternate port for local access
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      #INTERNAL-for communication between containers(kafkaserver:9092)
      #EXTERNAL-for communication from host(localhost:29092)
      #PLAINTEXT- protocol withowt shifrovanie(in prod use ssl)
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafkaserver:9092,EXTERNAL://localhost:29092 #Address which get clients
                            #kafkaserver
      KAFKA_LISTENERS: INTERNAL://kafkaserver:9092, EXTERNAL://0.0.0.0:29092
      #what listener we need to use for communication between brokers(if brokers not alone)
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      #auto create topics for develop
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: true
    healthcheck:
        test: [ "CMD-SHELL", "echo 'test-message' | kafka-console-producer.sh --broker-list localhost:9092 --topic health-check-topic && kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic health-check-topic --from-beginning --max-messages 1 | grep 'test-message'" ]
        interval: 15s
        timeout: 10s
        retries: 3
        # interval: 10s
        # timeout: 30s
        # retries: 15
    networks:
        backend-net:
          aliases:
            - kafkaserver

networks:
  backend-net:
    driver: bridge
volumes:
  db-data:
  db-data-two:
  myesdata: